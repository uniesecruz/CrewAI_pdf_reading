"""
Setup automÃ¡tico para LLMs locais gratuitos
Script universal (Windows/Linux/Mac)
"""
import subprocess
import sys
import os
import platform
from pathlib import Path

def print_header():
    """Imprime cabeÃ§alho do setup"""
    print("\n" + "=" * 60)
    print("   ğŸ¤– LLM PDF Reading - Setup Modelos Locais")
    print("   ğŸ¯ 100% Gratuito usando GPU local!")
    print("=" * 60)
    print()

def check_python_version():
    """Verifica versÃ£o do Python"""
    version = sys.version_info
    print(f"ğŸ Python detectado: {version.major}.{version.minor}.{version.micro}")
    
    if version.major < 3 or (version.major == 3 and version.minor < 10):
        print("âŒ Python 3.10+ requerido!")
        return False
    
    print("âœ… VersÃ£o do Python compatÃ­vel")
    return True

def check_project_structure():
    """Verifica estrutura do projeto"""
    print("ğŸ” Verificando estrutura do projeto...")
    
    # Navegar para diretÃ³rio do projeto
    script_dir = Path(__file__).parent
    project_dir = script_dir.parent
    os.chdir(project_dir)
    
    print(f"ğŸ“ DiretÃ³rio atual: {project_dir}")
    
    required_files = ["requirements.txt", "pyproject.toml"]
    for file in required_files:
        if not Path(file).exists():
            print(f"âŒ Arquivo {file} nÃ£o encontrado!")
            return False
    
    print("âœ… Estrutura do projeto verificada")
    return True

def install_dependencies():
    """Instala dependÃªncias do projeto"""
    print("\nğŸ“¦ Instalando dependÃªncias Python...")
    
    try:
        # Atualizar pip primeiro
        subprocess.run([sys.executable, "-m", "pip", "install", "--upgrade", "pip"], 
                      check=True, capture_output=True)
        
        # Instalar dependÃªncias
        subprocess.run([sys.executable, "-m", "pip", "install", "-r", "requirements.txt"], 
                      check=True)
        
        print("âœ… DependÃªncias instaladas com sucesso!")
        return True
        
    except subprocess.CalledProcessError as e:
        print("âŒ Erro ao instalar dependÃªncias!")
        print("\nğŸ’¡ PossÃ­veis soluÃ§Ãµes:")
        print("   1. Ative o ambiente virtual")
        print("   2. Verifique se o Python estÃ¡ no PATH")
        print("   3. Execute como administrador")
        print(f"   4. Erro: {e}")
        return False

def detect_gpu():
    """Detecta GPU disponÃ­vel"""
    print("\nğŸ” Verificando GPU...")
    
    gpu_info = {"nvidia": False, "cuda": False}
    
    try:
        result = subprocess.run(["nvidia-smi"], capture_output=True, text=True)
        if result.returncode == 0:
            gpu_info["nvidia"] = True
            print("âœ… GPU NVIDIA detectada!")
    except FileNotFoundError:
        print("âš ï¸  GPU NVIDIA nÃ£o detectada")
    
    return gpu_info

def install_pytorch(gpu_info):
    """Instala PyTorch baseado na GPU"""
    print("\nğŸ“¦ Instalando PyTorch...")
    
    try:
        if gpu_info["nvidia"]:
            print("ğŸ“¥ Instalando PyTorch com CUDA...")
            subprocess.run([
                sys.executable, "-m", "pip", "install", 
                "torch", "torchvision", "torchaudio", 
                "--index-url", "https://download.pytorch.org/whl/cu121"
            ], check=True)
        else:
            print("ğŸ“¥ Instalando PyTorch CPU...")
            subprocess.run([
                sys.executable, "-m", "pip", "install", 
                "torch", "torchvision", "torchaudio"
            ], check=True)
        
        print("âœ… PyTorch instalado com sucesso!")
        return True
        
    except subprocess.CalledProcessError:
        print("âš ï¸  Erro ao instalar PyTorch, mas continuando...")
        return False

def setup_ollama():
    """Configura Ollama"""
    print("\nğŸ¦™ Verificando Ollama...")
    
    try:
        result = subprocess.run(["ollama", "--version"], capture_output=True, text=True)
        if result.returncode == 0:
            print("âœ… Ollama detectado!")
            
            # Tentar baixar modelo
            print("ğŸ“¥ Baixando modelo llama2:7b...")
            try:
                subprocess.run(["ollama", "pull", "llama2:7b"], check=True, timeout=300)
                print("âœ… Modelo llama2:7b baixado!")
                return True
            except (subprocess.CalledProcessError, subprocess.TimeoutExpired):
                print("âš ï¸  Erro ao baixar modelo, mas Ollama estÃ¡ instalado")
                return True
    except FileNotFoundError:
        pass
    
    print("âŒ Ollama nÃ£o encontrado")
    print("\nğŸ’¡ Para instalar Ollama:")
    
    system = platform.system().lower()
    if system == "windows":
        print("   1. Baixe: https://ollama.ai/download/windows")
        print("   2. Execute o instalador")
    elif system == "darwin":
        print("   1. Baixe: https://ollama.ai/download/mac")
        print("   2. Ou use: brew install ollama")
    else:
        print("   1. Execute: curl -fsSL https://ollama.ai/install.sh | sh")
    
    return False

def test_system():
    """Testa o sistema"""
    print("\nğŸ§ª Testando sistema...")
    
    try:
        if Path("examples/local_llm_test.py").exists():
            subprocess.run([sys.executable, "examples/local_llm_test.py"], 
                          check=False, timeout=60)
        else:
            print("âš ï¸  Arquivo de teste nÃ£o encontrado")
    except subprocess.TimeoutExpired:
        print("âš ï¸  Teste demorou muito, mas isso Ã© normal")
    except Exception as e:
        print(f"âš ï¸  Erro no teste: {e}")

def show_next_steps():
    """Mostra prÃ³ximos passos"""
    print("\n" + "=" * 60)
    print("   ğŸ‰ Setup concluÃ­do!")
    print("=" * 60)
    print("\nğŸš€ PrÃ³ximos passos:")
    print("   1. Configure o arquivo .env se necessÃ¡rio")
    print("   2. Teste: python examples/local_llm_test.py")
    print("   3. Interface web: streamlit run apps/streamlit_app.py")
    print("\nğŸ’¡ Modelos recomendados para Ollama:")
    print("   - ollama pull llama2:7b      (Modelo geral)")
    print("   - ollama pull mistral:7b     (RÃ¡pido e eficiente)")
    print("   - ollama pull codellama:7b   (Para cÃ³digo)")
    print()

def main():
    """FunÃ§Ã£o principal do setup"""
    print_header()
    
    # VerificaÃ§Ãµes iniciais
    if not check_python_version():
        return False
    
    if not check_project_structure():
        return False
    
    # InstalaÃ§Ãµes
    if not install_dependencies():
        print("âš ï¸  Continuando mesmo com erro nas dependÃªncias...")
    
    gpu_info = detect_gpu()
    install_pytorch(gpu_info)
    
    # ConfiguraÃ§Ãµes
    ollama_ok = setup_ollama()
    
    # Teste
    test_system()
    
    # Finalizar
    show_next_steps()
    
    return True

if __name__ == "__main__":
    try:
        success = main()
        if not success:
            input("Pressione Enter para sair...")
            sys.exit(1)
    except KeyboardInterrupt:
        print("\nâŒ Setup cancelado pelo usuÃ¡rio")
    except Exception as e:
        print(f"\nâŒ Erro inesperado: {e}")
        input("Pressione Enter para sair...")
    else:
        input("Pressione Enter para sair...")
