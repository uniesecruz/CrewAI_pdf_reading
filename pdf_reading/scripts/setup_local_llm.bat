@echo off
title Setup LLM PDF Reading - Modelos Locais Gratuitos
color 0A

echo.
echo ================================================
echo   ğŸ¤– LLM PDF Reading - Setup Modelos Locais
echo   ğŸ¯ 100%% Gratuito usando GPU local!
echo ================================================
echo.

echo ğŸ“¦ Instalando dependencias Python...
pip install -r requirements.txt
if %errorlevel% neq 0 (
    echo âŒ Erro ao instalar dependencias!
    pause
    exit /b 1
)

echo.
echo âœ… Dependencias instaladas com sucesso!
echo.

echo ğŸ” Verificando GPU NVIDIA...
nvidia-smi >nul 2>&1
if %errorlevel% equ 0 (
    echo âœ… GPU NVIDIA detectada!
    echo ğŸ“¦ Instalando PyTorch com CUDA...
    pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121
) else (
    echo âš ï¸  GPU NVIDIA nao detectada, usando CPU
    echo ğŸ“¦ Instalando PyTorch CPU...
    pip install torch torchvision torchaudio
)

echo.
echo ğŸ¦™ Configurando Ollama...
echo.
echo IMPORTANTE: Para usar Ollama (recomendado):
echo 1. Baixe de: https://ollama.ai/download/windows
echo 2. Execute o instalador
echo 3. Reinicie este script
echo.

where ollama >nul 2>&1
if %errorlevel% equ 0 (
    echo âœ… Ollama detectado!
    echo ğŸ“¥ Baixando modelo llama2:7b...
    ollama pull llama2:7b
    if %errorlevel% equ 0 (
        echo âœ… Modelo llama2:7b baixado!
    ) else (
        echo âš ï¸  Erro ao baixar modelo, mas Ollama esta instalado
    )
) else (
    echo âŒ Ollama nao encontrado
    echo ğŸ’¡ Instale Ollama para usar modelos locais otimizados
)

echo.
echo ğŸ§ª Executando teste do sistema...
python examples/local_llm_test.py

echo.
echo ================================================
echo   ğŸ‰ Setup concluido!
echo ================================================
echo.
echo ğŸš€ Proximos passos:
echo   1. Configure o arquivo .env se necessario
echo   2. Teste: python examples/local_llm_test.py
echo   3. Interface web: streamlit run apps/streamlit_app.py
echo.
echo ğŸ’¡ Modelos recomendados para Ollama:
echo   - ollama pull llama2:7b      (Modelo geral)
echo   - ollama pull mistral:7b     (Rapido e eficiente)
echo   - ollama pull codellama:7b   (Para codigo)
echo.

pause
