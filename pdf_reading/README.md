# ğŸ¤– LLM PDF Reading - AnÃ¡lise Inteligente de PDFs

<a target="_blank" href="https://cookiecutter-data-science.drivendata.org/">
    <img src="https://img.shields.io/badge/CCDS-Project%20template-328F97?logo=cookiecutter" />
</a>
<img src="https://img.shields.io/badge/Python-3.12+-blue.svg" />
<img src="https://img.shields.io/badge/License-MIT-green.svg" />
<img src="https://img.shields.io/badge/Streamlit-1.47+-red.svg" />

Este projeto desenvolve uma soluÃ§Ã£o de **Large Language Model (LLM)** projetada para extraÃ§Ã£o, anÃ¡lise e sumarizaÃ§Ã£o eficiente e inteligente de conteÃºdo de documentos PDF. O objetivo principal Ã© transformar informaÃ§Ãµes estÃ¡ticas de PDFs em insights dinÃ¢micos e acionÃ¡veis, reduzindo significativamente o esforÃ§o manual tipicamente envolvido no processamento desses documentos.

## âœ¨ Funcionalidades

- ğŸ“„ **ExtraÃ§Ã£o Inteligente de PDF**: Suporte para mÃºltiplas bibliotecas (PyMuPDF, PyPDF2, pdfplumber)
- ğŸ¤– **LLMs Locais Gratuitos**: IntegraÃ§Ã£o com Ollama e Hugging Face Transformers
- â˜ï¸ **APIs Comerciais**: Suporte para OpenAI, Anthropic e Google
- ğŸ¯ **AnÃ¡lise AvanÃ§ada**: ExtraÃ§Ã£o de tÃ³picos principais, resumos automÃ¡ticos e mÃ©tricas
- â“ **Sistema de Q&A**: FaÃ§a perguntas sobre o documento e obtenha respostas contextuais
- ğŸ–¥ï¸ **Interface Web**: AplicaÃ§Ã£o Streamlit intuitiva e responsiva
- ğŸ”„ **Processamento por Chunks**: Otimizado para documentos grandes
- ğŸ“Š **VisualizaÃ§Ãµes**: MÃ©tricas de palavras, caracteres e tempo de leitura estimado

## ğŸš€ InÃ­cio RÃ¡pido

### PrÃ©-requisitos

- Python 3.12+
- GPU NVIDIA (opcional, para melhor performance)

### InstalaÃ§Ã£o

1. **Clone o repositÃ³rio**:
```bash
git clone https://github.com/uniesecruz/CrewAI_pdf_reading.git
cd CrewAI_pdf_reading
```

2. **Instale as dependÃªncias**:
```bash
pip install -r requirements.txt
```

3. **Configure modelos locais** (opcional):
```bash
# Para Ollama
curl -fsSL https://ollama.ai/install.sh | sh
ollama pull llama2:7b

# Para Hugging Face (automÃ¡tico na primeira execuÃ§Ã£o)
python scripts/setup_local_llm.py
```

### Uso

#### Interface Web (Recomendado)

```bash
streamlit run pdf_reading/apps/streamlit_app.py
```

Acesse `http://localhost:8501` no seu navegador.

#### Uso ProgramÃ¡tico

```python
from llm_pdf_reading.orchestrator import PDFReadingOrchestrator

# Configurar orquestrador
orchestrator = PDFReadingOrchestrator(use_local_models=True)

# Processar PDF
result = orchestrator.process_pdf("caminho/para/seu/arquivo.pdf")

# Fazer perguntas
answer = orchestrator.answer_question(
    result["content"], 
    "Qual Ã© o tema principal do documento?"
)
```

## ğŸ› ï¸ Tecnologias Utilizadas

### Core
- **CrewAI** (0.150.0): Framework para orquestraÃ§Ã£o de agentes AI
- **Streamlit** (1.47.1): Interface web interativa
- **PyTorch** (2.7.0): Framework de deep learning

### Processamento de PDF
- **PyMuPDF** (1.26.3): ExtraÃ§Ã£o rÃ¡pida e eficiente
- **PyPDF2** (3.0.1): ManipulaÃ§Ã£o de PDFs
- **pdfplumber** (0.11.7): AnÃ¡lise detalhada de layout

### LLMs Locais
- **Ollama**: Modelos como Llama 2, Mistral, CodeLlama
- **Hugging Face Transformers** (4.54.0): DialoGPT e outros modelos
- **CUDA Support**: AceleraÃ§Ã£o GPU automÃ¡tica

### APIs Comerciais
- **OpenAI**: GPT-3.5, GPT-4
- **Anthropic**: Claude 3
- **Google**: Gemini Pro

## ğŸ“ Estrutura do Projeto

```
pdf_reading/
â”œâ”€â”€ apps/
â”‚   â””â”€â”€ streamlit_app.py       <- Interface web principal
â”œâ”€â”€ llm_pdf_reading/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py              <- ConfiguraÃ§Ãµes centralizadas
â”‚   â”œâ”€â”€ orchestrator.py        <- Orquestrador principal
â”‚   â”œâ”€â”€ local_llm.py          <- Gerenciador de LLMs locais
â”‚   â”œâ”€â”€ pdf_utils.py          <- UtilitÃ¡rios para PDFs
â”‚   â””â”€â”€ text_processing.py    <- Processamento de texto
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ setup_local_llm.py    <- Script de configuraÃ§Ã£o
â”‚   â””â”€â”€ test_models.py        <- Testes de modelos
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ external/             <- PDFs de terceiros
â”‚   â”œâ”€â”€ processed/            <- Dados processados
â”‚   â””â”€â”€ raw/                  <- PDFs originais
â”œâ”€â”€ models/                   <- Modelos treinados/baixados
â”œâ”€â”€ requirements.txt          <- DependÃªncias do projeto
â””â”€â”€ README.md                <- Este arquivo
```

## âš™ï¸ ConfiguraÃ§Ã£o

### VariÃ¡veis de Ambiente

Crie um arquivo `.env` na raiz do projeto:

```env
# APIs Comerciais (opcional)
OPENAI_API_KEY=your_openai_key
ANTHROPIC_API_KEY=your_anthropic_key
GOOGLE_API_KEY=your_google_key

# ConfiguraÃ§Ãµes Ollama
OLLAMA_BASE_URL=http://localhost:11434
OLLAMA_DEFAULT_MODEL=llama2:7b

# ConfiguraÃ§Ãµes gerais
USE_LOCAL_MODELS=true
LOG_LEVEL=INFO
```

### Modelos Suportados

#### Ollama (Gratuito)
- `llama2:7b` - Modelo geral da Meta
- `mistral:7b` - Modelo rÃ¡pido e eficiente
- `codellama:7b` - Especializado em cÃ³digo
- `neural-chat:7b` - Otimizado para conversas

#### Hugging Face (Gratuito)
- `microsoft/DialoGPT-medium` - ConversaÃ§Ã£o
- `microsoft/DialoGPT-large` - ConversaÃ§Ã£o avanÃ§ada
- `facebook/blenderbot-400M-distill` - Chatbot compacto

## ğŸ“– Como Usar

### 1. Interface Web

1. **Inicie a aplicaÃ§Ã£o**:
   ```bash
   streamlit run pdf_reading/apps/streamlit_app.py
   ```

2. **Configure o modelo**:
   - Marque "Usar Modelos Locais" para modelos gratuitos
   - Selecione o modelo Ollama desejado (se disponÃ­vel)
   - Configure fallback para Hugging Face se necessÃ¡rio

3. **Processe um PDF**:
   - FaÃ§a upload de um arquivo PDF
   - Clique em "ğŸš€ Processar PDF"
   - Explore os resultados nas abas:
     - ğŸ“Š **AnÃ¡lise**: MÃ©tricas e resumo
     - ğŸ“ **ConteÃºdo**: Texto extraÃ­do
     - ğŸ“‹ **Metadados**: InformaÃ§Ãµes do arquivo
     - â“ **Perguntas**: Sistema de Q&A

4. **FaÃ§a perguntas**:
   - Digite uma pergunta sobre o documento
   - Clique em "Responder"
   - Visualize o histÃ³rico de perguntas

### 2. Uso ProgramÃ¡tico

```python
from llm_pdf_reading.orchestrator import PDFReadingOrchestrator

# ConfiguraÃ§Ã£o para modelos locais
config = {
    'use_ollama': True,
    'ollama_model': 'llama2:7b',
    'use_huggingface': True,
    'hf_model': 'microsoft/DialoGPT-medium'
}

# Inicializar orquestrador
orchestrator = PDFReadingOrchestrator(
    use_local_models=True,
    custom_config=config
)

# Processar PDF
result = orchestrator.process_pdf("documento.pdf")

if result["success"]:
    # AnÃ¡lise bÃ¡sica
    analysis = result["analysis"]
    print(f"Palavras: {analysis['word_count']}")
    print(f"Resumo: {analysis['summary']}")
    
    # Fazer perguntas
    resposta = orchestrator.answer_question(
        result["content"],
        "Quais sÃ£o os pontos principais?"
    )
    print(f"Resposta: {resposta}")
```

## ğŸ”§ Desenvolvimento

### Executar Testes

```bash
# Teste bÃ¡sico dos modelos
python scripts/test_models.py

# Teste da configuraÃ§Ã£o
python -c "from pdf_reading.llm_pdf_reading.config import *; print('âœ… Config OK')"
```

### Estrutura de Desenvolvimento

- `llm_pdf_reading/`: CÃ³digo principal do projeto
- `apps/`: AplicaÃ§Ãµes e interfaces
- `scripts/`: Scripts utilitÃ¡rios
- `tests/`: Testes automatizados

## ğŸ› SoluÃ§Ã£o de Problemas

### Ollama nÃ£o conecta
```bash
# Verificar se o Ollama estÃ¡ rodando
curl http://localhost:11434/api/tags

# Iniciar Ollama (se necessÃ¡rio)
ollama serve
```

### Erro de GPU
```bash
# Verificar CUDA
python -c "import torch; print(torch.cuda.is_available())"

# ForÃ§ar CPU se necessÃ¡rio
export CUDA_VISIBLE_DEVICES=""
```

### DependÃªncias faltando
```bash
# Reinstalar dependÃªncias
pip install -r requirements.txt --force-reinstall
```

## ğŸ“ˆ Performance

- **PDFs pequenos** (< 10 pÃ¡ginas): ~5-15 segundos
- **PDFs mÃ©dios** (10-50 pÃ¡ginas): ~30-60 segundos  
- **PDFs grandes** (> 50 pÃ¡ginas): ~2-5 minutos

*Performance com GPU pode ser 3-5x mais rÃ¡pida*

## ğŸ¤ ContribuiÃ§Ã£o

1. Fork o projeto
2. Crie uma branch para sua feature (`git checkout -b feature/AmazingFeature`)
3. Commit suas mudanÃ§as (`git commit -m 'Add some AmazingFeature'`)
4. Push para a branch (`git push origin feature/AmazingFeature`)
5. Abra um Pull Request

## ğŸ“„ LicenÃ§a

Este projeto estÃ¡ licenciado sob a LicenÃ§a MIT - veja o arquivo [LICENSE](LICENSE) para detalhes.

## ğŸ‘¥ Autores

- **uniesecruz** - *Desenvolvimento inicial* - [GitHub](https://github.com/uniesecruz)

## ğŸ™ Agradecimentos

- [CrewAI](https://crewai.com/) - Framework de orquestraÃ§Ã£o
- [Ollama](https://ollama.ai/) - Modelos locais gratuitos
- [Hugging Face](https://huggingface.co/) - Transformers e modelos
- [Streamlit](https://streamlit.io/) - Interface web

---

â­ **Se este projeto foi Ãºtil para vocÃª, considere dar uma estrela!**

